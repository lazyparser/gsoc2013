# HG changeset patch
# Parent 308e3cf5ba75fdf8ed3bdd3dc766410b708b98ef
# User Wei Wu <lazyparser@gmail.com>

diff --git a/js/src/ion/BaselineCompiler.cpp b/js/src/ion/BaselineCompiler.cpp
--- a/js/src/ion/BaselineCompiler.cpp
+++ b/js/src/ion/BaselineCompiler.cpp
@@ -144,17 +144,18 @@ BaselineCompiler::compile()
 
     prologueOffset_.fixup(&masm);
     spsPushToggleOffset_.fixup(&masm);
 
     BaselineScript *baselineScript = BaselineScript::New(cx, prologueOffset_.offset(),
                                                          spsPushToggleOffset_.offset(),
                                                          icEntries_.length(),
                                                          pcMappingIndexEntries.length(),
-                                                         pcEntries.length());
+                                                         pcEntries.length(),
+                                                         blockCounterEntries_.length());
     if (!baselineScript)
         return Method_Error;
 
     baselineScript->setMethod(code);
 
     script->setBaselineScript(baselineScript);
 
     IonSpew(IonSpew_BaselineScripts, "Created BaselineScript %p (raw %p) for %s:%d",
@@ -180,24 +181,47 @@ BaselineCompiler::compile()
         label.fixup(&masm);
         size_t icEntry = icLoadLabels_[i].icEntry;
         ICEntry *entryAddr = &(baselineScript->icEntry(icEntry));
         Assembler::patchDataWithValueCheck(CodeLocationLabel(code, label),
                                            ImmWord(uintptr_t(entryAddr)),
                                            ImmWord(uintptr_t(-1)));
     }
 
+    IonSpew(IonSpew_BranchProfiles,
+            "[BaselineCompiler] Statistics %d counters emitted for script %s:%d (%p)",
+            blockCounterEntries_.length(), script->filename(),
+            script->lineno, script->baselineScript());
+
+    if (blockCounterEntries_.length())
+        baselineScript->copyBlockCounterEntries(&blockCounterEntries_[0]);
+
+    // Patch block counters
+    for (size_t i = 0; i < blockCounterLabels_.length(); i++) {
+        CodeOffsetLabel label = blockCounterLabels_[i].label;
+        label.fixup(&masm);
+        size_t bcEntry = blockCounterLabels_[i].bcEntry;
+        BlockCounterEntry *bcEntryAddr = &baselineScript->blockCounterEntry(bcEntry);
+        Assembler::patchDataWithValueCheck(CodeLocationLabel(code, label),
+                                           ImmWord(uintptr_t(bcEntryAddr)),
+                                           ImmWord(uintptr_t(-1)));
+        bcEntryAddr->toggleOffset.fixup(&masm);
+    }
+
     // All barriers are emitted off-by-default, toggle them on if needed.
     if (cx->zone()->needsBarrier())
         baselineScript->toggleBarriers(true);
 
     // All SPS instrumentation is emitted toggled off.  Toggle them on if needed.
     if (cx->runtime()->spsProfiler.enabled())
         baselineScript->toggleSPS(true);
 
+    if (js_IonOptions.baselineBranchProfiling)
+        baselineScript->toggleBlockCounters(true);
+
     return Method_Compiled;
 }
 
 bool
 BaselineCompiler::emitPrologue()
 {
     masm.push(BaselineFrameReg);
     masm.mov(BaselineStackReg, BaselineFrameReg);
@@ -321,16 +345,46 @@ BaselineCompiler::emitIC(ICStub *stub, b
     EmitCallIC(&patchOffset, masm);
     entry->setReturnOffset(masm.currentOffset());
     if (!addICLoadLabel(patchOffset))
         return false;
 
     return true;
 }
 
+bool
+BaselineCompiler::emitBlockCounter(jsbytecode *pc)
+{
+    if (!ionCompileable_ && !ionOSRCompileable_)
+        return true;
+
+    IonSpew(IonSpew_BranchProfiles, "[emitBlockCounter] op @ %d: %s",
+            int(pc - script->code), js_CodeName[JSOp(*pc)]);
+
+    BlockCounterEntry *entry = allocateBlockCounterEntry(pc - script->code);
+    if(!entry)
+        return false;
+
+    Label skipCount;
+    CodeOffsetLabel toggleOffset = masm.toggledJump(&skipCount);
+    entry->toggleOffset = toggleOffset;
+
+    Register addressReg = R1.scratchReg();
+    CodeOffsetLabel counterOffset = masm.movWithPatch(ImmWord(-1), addressReg);
+    Address counterAddr(addressReg, BlockCounterEntry::offsetOfCounter());
+    masm.add32(Imm32(1), counterAddr);
+
+    masm.bind(&skipCount);
+
+    if(!addBlockCounterLabel(counterOffset))
+        return false;
+
+    return true;
+}
+
 typedef bool (*DebugPrologueFn)(JSContext *, BaselineFrame *, JSBool *);
 static const VMFunction DebugPrologueInfo = FunctionInfo<DebugPrologueFn>(ion::DebugPrologue);
 
 bool
 BaselineCompiler::emitDebugPrologue()
 {
     if (!debugMode_)
         return true;
@@ -615,16 +669,23 @@ BaselineCompiler::emitBody()
             emittedOps = 0;
         if (!addPCMappingEntry(addIndexEntry))
             return Method_Error;
 
         // Emit traps for breakpoints and step mode.
         if (debugMode_ && !emitDebugTrap())
             return Method_Error;
 
+        if (js_IonOptions.baselineBranchProfiling) {
+            // Instrument all jump targets and the first opcode.
+            if ( (pc == script->code || info->jumpTarget ) && !emitBlockCounter(pc))
+                return Method_Error;
+        }
+
+
         switch (op) {
           default:
             IonSpew(IonSpew_BaselineAbort, "Unhandled op: %s", js_CodeName[op]);
             return Method_CantCompile;
 
 #define EMIT_OP(OP)                            \
           case OP:                             \
             if (!this->emit_##OP())            \
diff --git a/js/src/ion/BaselineCompiler.h b/js/src/ion/BaselineCompiler.h
--- a/js/src/ion/BaselineCompiler.h
+++ b/js/src/ion/BaselineCompiler.h
@@ -213,16 +213,18 @@ class BaselineCompiler : public Baseline
     bool emitIC(ICStub *stub, bool isForOp);
     bool emitOpIC(ICStub *stub) {
         return emitIC(stub, true);
     }
     bool emitNonOpIC(ICStub *stub) {
         return emitIC(stub, false);
     }
 
+    bool emitBlockCounter(jsbytecode *pc);
+
     bool emitStackCheck();
     bool emitInterruptCheck();
     bool emitUseCountIncrement();
     bool emitArgumentTypeChecks();
     bool emitDebugPrologue();
     bool emitDebugTrap();
     bool emitSPSPush();
     void emitSPSPop();
diff --git a/js/src/ion/BaselineJIT.cpp b/js/src/ion/BaselineJIT.cpp
--- a/js/src/ion/BaselineJIT.cpp
+++ b/js/src/ion/BaselineJIT.cpp
@@ -329,31 +329,35 @@ ion::CanEnterBaselineMethod(JSContext *c
 };
 
 // Be safe, align IC entry list to 8 in all cases.
 static const unsigned DataAlignment = sizeof(uintptr_t);
 
 BaselineScript *
 BaselineScript::New(JSContext *cx, uint32_t prologueOffset,
                     uint32_t spsPushToggleOffset, size_t icEntries,
-                    size_t pcMappingIndexEntries, size_t pcMappingSize)
+                    size_t pcMappingIndexEntries, size_t pcMappingSize,
+                    size_t blockCounters)
 {
     size_t paddedBaselineScriptSize = AlignBytes(sizeof(BaselineScript), DataAlignment);
 
     size_t icEntriesSize = icEntries * sizeof(ICEntry);
     size_t pcMappingIndexEntriesSize = pcMappingIndexEntries * sizeof(PCMappingIndexEntry);
+    size_t blockCounterSize = blockCounters * sizeof(BlockCounterEntry);
 
     size_t paddedICEntriesSize = AlignBytes(icEntriesSize, DataAlignment);
     size_t paddedPCMappingIndexEntriesSize = AlignBytes(pcMappingIndexEntriesSize, DataAlignment);
     size_t paddedPCMappingSize = AlignBytes(pcMappingSize, DataAlignment);
+    size_t paddedBlockCounterSize = AlignBytes(blockCounterSize, DataAlignment);
 
     size_t allocBytes = paddedBaselineScriptSize +
         paddedICEntriesSize +
         paddedPCMappingIndexEntriesSize +
-        paddedPCMappingSize;
+        paddedPCMappingSize +
+        paddedBlockCounterSize;
 
     uint8_t *buffer = (uint8_t *)cx->malloc_(allocBytes);
     if (!buffer)
         return NULL;
 
     BaselineScript *script = reinterpret_cast<BaselineScript *>(buffer);
     new (script) BaselineScript(prologueOffset, spsPushToggleOffset);
 
@@ -366,16 +370,20 @@ BaselineScript::New(JSContext *cx, uint3
     script->pcMappingIndexOffset_ = offsetCursor;
     script->pcMappingIndexEntries_ = pcMappingIndexEntries;
     offsetCursor += paddedPCMappingIndexEntriesSize;
 
     script->pcMappingOffset_ = offsetCursor;
     script->pcMappingSize_ = pcMappingSize;
     offsetCursor += paddedPCMappingSize;
 
+    script->blockCounterOffset_ = offsetCursor;
+    script->blockCounters_ = blockCounters;
+    offsetCursor += paddedBlockCounterSize;
+
     return script;
 }
 
 void
 BaselineScript::trace(JSTracer *trc)
 {
     MarkIonCode(trc, &method_, "baseline-method");
 
@@ -391,16 +399,32 @@ BaselineScript::trace(JSTracer *trc)
 
 void
 BaselineScript::Trace(JSTracer *trc, BaselineScript *script)
 {
     script->trace(trc);
 }
 
 void
+BaselineScript::DumpBlockCounters(BaselineScript *script)
+{
+#ifdef DEBUG
+    BlockCounterEntry *entries = script->blockCounterEntryList();
+    size_t length = script->numBlockCounters();
+    IonSpew(IonSpew_BranchProfiles,
+            "[DumpBlockCounters] Statistics %zu counters for baselineScript %p",
+            length, script);
+    for (size_t i = 0;i < length; i++) {
+        IonSpew(IonSpew_BranchProfiles, "[DumpBlockCounters] offset %zu value %u",
+                entries[i].pcOffset, entries[i].counter);
+    }
+#endif
+}
+
+void
 BaselineScript::Destroy(FreeOp *fop, BaselineScript *script)
 {
     fop->delete_(script);
 }
 
 ICEntry &
 BaselineScript::icEntry(size_t index)
 {
@@ -410,16 +434,23 @@ BaselineScript::icEntry(size_t index)
 
 PCMappingIndexEntry &
 BaselineScript::pcMappingIndexEntry(size_t index)
 {
     JS_ASSERT(index < numPCMappingIndexEntries());
     return pcMappingIndexEntryList()[index];
 }
 
+BlockCounterEntry &
+BaselineScript::blockCounterEntry(size_t index)
+{
+    JS_ASSERT(index < numBlockCounters());
+    return blockCounterEntryList()[index];
+}
+
 CompactBufferReader
 BaselineScript::pcMappingReader(size_t indexEntry)
 {
     PCMappingIndexEntry &entry = pcMappingIndexEntry(indexEntry);
 
     uint8_t *dataStart = pcMappingData() + entry.bufferOffset;
     uint8_t *dataEnd = (indexEntry == numPCMappingIndexEntries() - 1)
         ? pcMappingData() + pcMappingSize_
@@ -566,16 +597,25 @@ BaselineScript::copyICEntries(HandleScri
         if (realEntry.firstStub()->isTableSwitch()) {
             ICTableSwitch *stub = realEntry.firstStub()->toTableSwitch();
             stub->fixupJumpTable(script, this);
         }
     }
 }
 
 void
+BaselineScript::copyBlockCounterEntries(BlockCounterEntry *entries)
+{
+    for (uint32_t i = 0; i < numBlockCounters(); i++) {
+        BlockCounterEntry &entry = blockCounterEntry(i);
+        entry = entries[i];
+    }
+}
+
+void
 BaselineScript::adoptFallbackStubs(FallbackICStubSpace *stubSpace)
 {
     fallbackStubSpace_.adoptFrom(stubSpace);
 }
 
 void
 BaselineScript::copyPCMappingEntries(const CompactBufferWriter &entries)
 {
@@ -750,16 +790,29 @@ BaselineScript::toggleSPS(bool enable)
         Assembler::ToggleToCmp(pushToggleLocation);
     else
         Assembler::ToggleToJmp(pushToggleLocation);
 #ifdef DEBUG
     spsOn_ = enable;
 #endif
 }
 
+
+void
+BaselineScript::toggleBlockCounters(bool enable)
+{
+    for (size_t i = 0; i < blockCounters_; i++) {
+        CodeLocationLabel counterToggleLocation(method_, blockCounterEntry(i).toggleOffset);
+        if (enable)
+            Assembler::ToggleToCmp(counterToggleLocation);
+        else
+            Assembler::ToggleToJmp(counterToggleLocation);
+    }
+}
+
 void
 BaselineScript::purgeOptimizedStubs(Zone *zone)
 {
     IonSpew(IonSpew_BaselineIC, "Purging optimized stubs");
 
     for (size_t i = 0; i < numICEntries(); i++) {
         ICEntry &entry = icEntry(i);
         if (!entry.hasStub())
diff --git a/js/src/ion/BaselineJIT.h b/js/src/ion/BaselineJIT.h
--- a/js/src/ion/BaselineJIT.h
+++ b/js/src/ion/BaselineJIT.h
@@ -91,16 +91,30 @@ struct PCMappingIndexEntry
 
     // Native code offset.
     uint32_t nativeOffset;
 
     // Offset in the CompactBuffer where data for pcOffset starts.
     uint32_t bufferOffset;
 };
 
+struct BlockCounterEntry
+{
+    uint32_t counter;
+    size_t pcOffset;
+    CodeOffsetLabel toggleOffset;
+    BlockCounterEntry(const size_t pcoffset)
+      : counter(0),
+        pcOffset(pcoffset)
+    { }
+    static size_t offsetOfCounter() {
+        return offsetof(BlockCounterEntry, counter);
+    }
+};
+
 struct BaselineScript
 {
   public:
     static const uint32_t MAX_JSSCRIPT_LENGTH = 0x0fffffffu;
 
   private:
     // Code pointer containing the actual method.
     HeapPtr<IonCode> method_;
@@ -138,24 +152,29 @@ struct BaselineScript
     uint32_t icEntries_;
 
     uint32_t pcMappingIndexOffset_;
     uint32_t pcMappingIndexEntries_;
 
     uint32_t pcMappingOffset_;
     uint32_t pcMappingSize_;
 
+    uint32_t blockCounterOffset_;
+    uint32_t blockCounters_;
+
   public:
     // Do not call directly, use BaselineScript::New. This is public for cx->new_.
     BaselineScript(uint32_t prologueOffset, uint32_t spsPushToggleOffset);
 
     static BaselineScript *New(JSContext *cx, uint32_t prologueOffset,
                                uint32_t spsPushToggleOffset, size_t icEntries,
-                               size_t pcMappingIndexEntries, size_t pcMappingSize);
+                               size_t pcMappingIndexEntries, size_t pcMappingSize,
+                               size_t blockCounters);
     static void Trace(JSTracer *trc, BaselineScript *script);
+    static void DumpBlockCounters(BaselineScript *script);
     static void Destroy(FreeOp *fop, BaselineScript *script);
 
     void purgeOptimizedStubs(Zone *zone);
 
     static inline size_t offsetOfMethod() {
         return offsetof(BaselineScript, method_);
     }
 
@@ -197,16 +216,20 @@ struct BaselineScript
     }
     uint8_t *pcMappingData() {
         return reinterpret_cast<uint8_t *>(this) + pcMappingOffset_;
     }
     FallbackICStubSpace *fallbackStubSpace() {
         return &fallbackStubSpace_;
     }
 
+    BlockCounterEntry *blockCounterEntryList() {
+        return (BlockCounterEntry *)(reinterpret_cast<uint8_t *>(this) + blockCounterOffset_);
+    }
+
     IonCode *method() const {
         return method_;
     }
     void setMethod(IonCode *code) {
         JS_ASSERT(!method_);
         method_ = code;
     }
 
@@ -228,20 +251,27 @@ struct BaselineScript
     }
 
     void copyICEntries(HandleScript script, const ICEntry *entries, MacroAssembler &masm);
     void adoptFallbackStubs(FallbackICStubSpace *stubSpace);
 
     PCMappingIndexEntry &pcMappingIndexEntry(size_t index);
     CompactBufferReader pcMappingReader(size_t indexEntry);
 
+    BlockCounterEntry &blockCounterEntry(size_t index);
+    void copyBlockCounterEntries(BlockCounterEntry *entries);
+
     size_t numPCMappingIndexEntries() const {
         return pcMappingIndexEntries_;
     }
 
+    size_t numBlockCounters() const {
+        return blockCounters_;
+    }
+
     void copyPCMappingIndexEntries(const PCMappingIndexEntry *entries);
 
     void copyPCMappingEntries(const CompactBufferWriter &entries);
     uint8_t *nativeCodeForPC(JSScript *script, jsbytecode *pc, PCMappingSlotInfo *slotInfo = NULL);
     jsbytecode *pcForReturnOffset(JSScript *script, uint32_t nativeOffset);
     jsbytecode *pcForReturnAddress(JSScript *script, uint8_t *nativeAddress);
 
     // Toggle debug traps (used for breakpoints and step mode) in the script.
@@ -251,16 +281,22 @@ struct BaselineScript
 
     void toggleSPS(bool enable);
 
     void noteAccessedGetter(uint32_t pcOffset);
 
     static size_t offsetOfFlags() {
         return offsetof(BaselineScript, flags_);
     }
+
+    static size_t offsetOfBlockCounterOffset(){
+        return offsetof(BaselineScript, blockCounterOffset_);
+    }
+
+    void toggleBlockCounters(bool enable);
 };
 
 inline bool
 IsBaselineEnabled(JSContext *cx)
 {
     return cx->hasOption(JSOPTION_BASELINE);
 }
 
diff --git a/js/src/ion/Ion.cpp b/js/src/ion/Ion.cpp
--- a/js/src/ion/Ion.cpp
+++ b/js/src/ion/Ion.cpp
@@ -970,16 +970,24 @@ OptimizeMIR(MIRGenerator *mir)
     if (!RenumberBlocks(graph))
         return false;
     IonSpewPass("Renumber Blocks");
     AssertGraphCoherency(graph);
 
     if (mir->shouldCancel("Renumber Blocks"))
         return false;
 
+    if (js_IonOptions.baselineBranchProfiling && !AttachBranchProfiles(graph))
+        return false;
+    IonSpewPass("Attach Branch Profiles");
+    AssertGraphCoherency(graph);
+
+    if (mir->shouldCancel("Attach Branch Profiles"))
+        return false;
+
     if (!BuildDominatorTree(graph))
         return false;
     // No spew: graph not changed.
 
     if (mir->shouldCancel("Dominator Tree"))
         return false;
 
     // This must occur before any code elimination.
@@ -1359,16 +1367,21 @@ IonCompile(JSContext *cx, JSScript *scri
 {
 #if JS_TRACE_LOGGING
     AutoTraceLog logger(TraceLogging::defaultLogger(),
                         TraceLogging::ION_COMPILE_START,
                         TraceLogging::ION_COMPILE_STOP,
                         script);
 #endif
 
+#ifdef DEBUG
+    if (js_IonOptions.baselineBranchProfiling && script->hasBaselineScript())
+        BaselineScript::DumpBlockCounters(script->baselineScript());
+#endif
+
     if (!script->ensureRanAnalysis(cx))
         return AbortReason_Alloc;
 
     LifoAlloc *alloc = cx->new_<LifoAlloc>(BUILDER_LIFO_ALLOC_PRIMARY_CHUNK_SIZE);
     if (!alloc)
         return AbortReason_Alloc;
 
     ScopedJSDeletePtr<LifoAlloc> autoDelete(alloc);
diff --git a/js/src/ion/Ion.h b/js/src/ion/Ion.h
--- a/js/src/ion/Ion.h
+++ b/js/src/ion/Ion.h
@@ -174,16 +174,21 @@ struct IonOptions
     // Default: false
     bool eagerCompilation;
 
     // How many uses of a parallel kernel before we attempt compilation.
     //
     // Default: 1
     uint32_t usesBeforeCompileParallel;
 
+    // Whether baseline scripts are instrumented.
+    //
+    // Default: true
+    bool baselineBranchProfiling;
+
     void setEagerCompilation() {
         eagerCompilation = true;
         usesBeforeCompile = 0;
         baselineUsesBeforeCompile = 0;
 
         parallelCompilation = false;
     }
 
@@ -208,17 +213,18 @@ struct IonOptions
         maxStackArgs(4096),
         maxInlineDepth(3),
         smallFunctionMaxInlineDepth(10),
         smallFunctionMaxBytecodeLength(100),
         polyInlineMax(4),
         inlineMaxTotalBytecodeLength(1000),
         inlineUseCountRatio(128),
         eagerCompilation(false),
-        usesBeforeCompileParallel(1)
+        usesBeforeCompileParallel(1),
+        baselineBranchProfiling(true)
     {
     }
 
     uint32_t usesBeforeInlining() {
         return usesBeforeCompile * usesBeforeInliningFactor;
     }
 };
 
diff --git a/js/src/ion/IonAnalysis.cpp b/js/src/ion/IonAnalysis.cpp
--- a/js/src/ion/IonAnalysis.cpp
+++ b/js/src/ion/IonAnalysis.cpp
@@ -6,16 +6,17 @@
 
 #include "jsanalyze.h"
 
 #include "ion/IonBuilder.h"
 #include "ion/MIRGraph.h"
 #include "ion/Ion.h"
 #include "ion/IonAnalysis.h"
 #include "ion/LIR.h"
+#include "ion/BaselineJIT.h"
 
 using namespace js;
 using namespace js::ion;
 
 // A critical edge is an edge which is neither its successor's only predecessor
 // nor its predecessor's only successor. Critical edges must be split to
 // prevent copy-insertion and code motion from affecting other edges.
 bool
@@ -36,16 +37,69 @@ ion::SplitCriticalEdges(MIRGraph &graph)
             split->end(MGoto::New(target));
 
             block->replaceSuccessor(i, split);
             target->replacePredecessor(*block, split);
         }
     }
     return true;
 }
+inline bool
+ion::isAsmJSCompilation(MIRGraph &graph)
+{
+    return graph.numScripts() == 0;
+}
+bool
+ion::AttachBranchProfiles(MIRGraph &graph)
+{
+    // Skip AsmJs MIRGraphs.
+    if (isAsmJSCompilation(graph))
+        return true;
+
+    for (MBasicBlockIterator block(graph.begin()); block != graph.end(); block++) {
+        CompileInfo &info = block->info();
+        jsbytecode *code = info.startPC();
+        JSScript *jsscript = info.script();
+        if (!jsscript || !jsscript->hasBaselineScript())
+            continue;
+        BaselineScript *blscript = jsscript->baselineScript();
+
+        jsbytecode *pc = block->pc();
+
+        // Not all blocks have a pc, only blocks which have a resume point.
+        if (!pc)
+            continue;
+
+        // In baseline compiler we instrument 'JSOP_LOOPHEAD', while IonBuilder
+        // might assign the pc of previous opcode (JSOP_NOP or JSOP_GOTO)
+        // to corresponding MBasicBlock. These mismatch can be corrected
+        // by adding the length of the previous opcode.
+        int loopHeaderOffset = 0;
+        JSOp op = JSOp(*pc);
+        if (block->isLoopHeader()) {
+            if(op == JSOP_NOP || op == JSOP_GOTO)
+                loopHeaderOffset = GetBytecodeLength(pc);
+            else
+                JS_ASSERT(op == JSOP_LOOPHEAD);
+        }
+
+        // Since the value of numCounters is usually less than 10,
+        // the linear search algorithm is fast enough.
+        // We can switch to binary search if necessary.
+        size_t numCounters = blscript->numBlockCounters();
+        for (size_t i = 0; i < numCounters; i++) {
+            BlockCounterEntry entry = blscript->blockCounterEntry(i);
+            if (entry.pcOffset + code == pc + loopHeaderOffset) {
+                block->setBlockUseCount(entry.counter);
+                break;
+            }
+        }
+    }
+    return true;
+}
 
 // Operands to a resume point which are dead at the point of the resume can be
 // replaced with undefined values. This analysis supports limited detection of
 // dead operands, pruning those which are defined in the resume point's basic
 // block and have no uses outside the block or at points later than the resume
 // point.
 //
 // This is intended to ensure that extra resume points within a basic block
diff --git a/js/src/ion/IonAnalysis.h b/js/src/ion/IonAnalysis.h
--- a/js/src/ion/IonAnalysis.h
+++ b/js/src/ion/IonAnalysis.h
@@ -16,16 +16,22 @@ namespace js {
 namespace ion {
 
 class MIRGenerator;
 class MIRGraph;
 
 bool
 SplitCriticalEdges(MIRGraph &graph);
 
+bool
+AttachBranchProfiles(MIRGraph &graph);
+
+bool
+isAsmJSCompilation(MIRGraph &graph);
+
 enum Observability {
     ConservativeObservability,
     AggressiveObservability
 };
 
 bool
 EliminatePhis(MIRGenerator *mir, MIRGraph &graph, Observability observe);
 
diff --git a/js/src/ion/IonSpewer.cpp b/js/src/ion/IonSpewer.cpp
--- a/js/src/ion/IonSpewer.cpp
+++ b/js/src/ion/IonSpewer.cpp
@@ -239,16 +239,18 @@ ion::CheckLogging()
             "  bailouts   Bailouts\n"
             "  caches     Inline caches\n"
             "  osi        Invalidation\n"
             "  safepoints Safepoints\n"
             "  pools      Literal Pools (ARM only for now)\n"
             "  cacheflush Instruction Cache flushes (ARM only for now)\n"
             "  logs       C1 and JSON visualization logging\n"
             "  trace      Generate calls to js::ion::Trace() for effectful instructions\n"
+            "  branchprofiles\n"
+            "             Dump branch profiling data\n"
             "  all        Everything\n"
             "\n"
             "  bl-aborts  Baseline compiler abort messages\n"
             "  bl-scripts Baseline script-compilation\n"
             "  bl-op      Baseline compiler detailed op-specific messages\n"
             "  bl-ic      Baseline inline-cache messages\n"
             "  bl-ic-fb   Baseline IC fallback stub messages\n"
             "  bl-osr     Baseline IC OSR messages\n"
@@ -292,16 +294,18 @@ ion::CheckLogging()
     if (ContainsFlag(env, "pools"))
         EnableChannel(IonSpew_Pools);
     if (ContainsFlag(env, "cacheflush"))
         EnableChannel(IonSpew_CacheFlush);
     if (ContainsFlag(env, "logs"))
         EnableIonDebugLogging();
     if (ContainsFlag(env, "trace"))
         EnableChannel(IonSpew_Trace);
+    if (ContainsFlag(env, "branchprofiles"))
+        EnableChannel(IonSpew_BranchProfiles);
     if (ContainsFlag(env, "all"))
         LoggingBits = uint32_t(-1);
 
     if (ContainsFlag(env, "bl-aborts"))
         EnableChannel(IonSpew_BaselineAbort);
     if (ContainsFlag(env, "bl-scripts"))
         EnableChannel(IonSpew_BaselineScripts);
     if (ContainsFlag(env, "bl-op"))
diff --git a/js/src/ion/IonSpewer.h b/js/src/ion/IonSpewer.h
--- a/js/src/ion/IonSpewer.h
+++ b/js/src/ion/IonSpewer.h
@@ -50,16 +50,18 @@ namespace ion {
     /* Debug info about safepoints */       \
     _(Safepoints)                           \
     /* Debug info about Pools*/             \
     _(Pools)                                \
     /* Calls to js::ion::Trace() */         \
     _(Trace)                                \
     /* Debug info about the I$ */           \
     _(CacheFlush)                           \
+    /* Branch Profiling */                  \
+    _(BranchProfiles)                       \
                                             \
     /* BASELINE COMPILER SPEW */            \
                                             \
     /* Aborting Script Compilation. */      \
     _(BaselineAbort)                        \
     /* Script Compilation. */               \
     _(BaselineScripts)                      \
     /* Detailed op-specific spew. */        \
diff --git a/js/src/ion/MIRGraph.cpp b/js/src/ion/MIRGraph.cpp
--- a/js/src/ion/MIRGraph.cpp
+++ b/js/src/ion/MIRGraph.cpp
@@ -247,17 +247,19 @@ MBasicBlock::MBasicBlock(MIRGraph &graph
     successorWithPhis_(NULL),
     positionInPhiSuccessor_(0),
     kind_(kind),
     loopDepth_(0),
     mark_(false),
     immediateDominator_(NULL),
     numDominated_(0),
     loopHeader_(NULL),
-    trackedPc_(pc)
+    trackedPc_(pc),
+    blockUseCount_(0),
+    blockUseCountAvailable_(false)
 #if defined (JS_ION_PERF)
     , lineno_(0u),
     columnIndex_(0u)
 #endif
 {
 }
 
 bool
diff --git a/js/src/ion/MIRGraph.h b/js/src/ion/MIRGraph.h
--- a/js/src/ion/MIRGraph.h
+++ b/js/src/ion/MIRGraph.h
@@ -476,16 +476,38 @@ class MBasicBlock : public TempObject, p
     void updateTrackedPc(jsbytecode *pc) {
         trackedPc_ = pc;
     }
 
     jsbytecode *trackedPc() {
         return trackedPc_;
     }
 
+    // SplitCriticalEdges() may introduce new MBasicBlocks,
+    // which has no profile available.
+    bool isBlockUseCountAvailable() {
+        return blockUseCountAvailable_;
+    }
+    void setBlockUseCount(const uint32_t useCount) {
+        blockUseCount_ = useCount;
+        blockUseCountAvailable_ = true;
+    }
+
+    uint32_t getBlockUseCount() {
+        return blockUseCount_;
+    }
+
+    bool isWorthFiltered() {
+        uint32_t scriptUseCount = info_.script()->getUseCount();
+        // TODO: Decide whether this block is worth to be filtered out.
+        if (isBlockUseCountAvailable() && getBlockUseCount() < scriptUseCount / 10)
+            return true;
+        return false;
+    }
+
   private:
     MIRGraph &graph_;
     CompileInfo &info_; // Each block originates from a particular script.
     InlineList<MInstruction> instructions_;
     Vector<MBasicBlock *, 1, IonAllocPolicy> predecessors_;
     InlineForwardList<MPhi> phis_;
     InlineForwardList<MResumePoint> resumePoints_;
     FixedList<MDefinition *> slots_;
@@ -496,16 +518,18 @@ class MBasicBlock : public TempObject, p
     uint32_t domIndex_; // Index in the dominator tree.
     LBlock *lir_;
     MStart *start_;
     MResumePoint *entryResumePoint_;
     MBasicBlock *successorWithPhis_;
     uint32_t positionInPhiSuccessor_;
     Kind kind_;
     uint32_t loopDepth_;
+    uint32_t blockUseCount_;
+    bool blockUseCountAvailable_;
 
     // Utility mark for traversal algorithms.
     bool mark_;
 
     Vector<MBasicBlock *, 1, IonAllocPolicy> immediatelyDominated_;
     MBasicBlock *immediateDominator_;
     size_t numDominated_;
     MBasicBlock *loopHeader_;
diff --git a/js/src/ion/shared/BaselineCompiler-shared.h b/js/src/ion/shared/BaselineCompiler-shared.h
--- a/js/src/ion/shared/BaselineCompiler-shared.h
+++ b/js/src/ion/shared/BaselineCompiler-shared.h
@@ -28,16 +28,17 @@ class BaselineCompilerShared
     bool ionOSRCompileable_;
     bool debugMode_;
 
     BytecodeAnalysis analysis_;
     FrameInfo frame;
 
     FallbackICStubSpace stubSpace_;
     js::Vector<ICEntry, 16, SystemAllocPolicy> icEntries_;
+    js::Vector<BlockCounterEntry, 16, SystemAllocPolicy> blockCounterEntries_;
 
     // Stores the native code offset for a bytecode pc.
     struct PCMappingEntry
     {
         uint32_t pcOffset;
         uint32_t nativeOffset;
         PCMappingSlotInfo slotInfo;
 
@@ -60,16 +61,22 @@ class BaselineCompilerShared
     // to be patched with the actual icEntry offsets after the BaselineScript
     // has been allocated.
     struct ICLoadLabel {
         size_t icEntry;
         CodeOffsetLabel label;
     };
     js::Vector<ICLoadLabel, 16, SystemAllocPolicy> icLoadLabels_;
 
+    struct BlockCounterLabel {
+        size_t bcEntry;
+        CodeOffsetLabel label;
+    };
+    js::Vector<BlockCounterLabel, 16, SystemAllocPolicy> blockCounterLabels_;
+
     uint32_t pushedBeforeCall_;
     mozilla::DebugOnly<bool> inCall_;
 
     CodeOffsetLabel spsPushToggleOffset_;
 
     BaselineCompilerShared(JSContext *cx, HandleScript script);
 
     ICEntry *allocateICEntry(ICStub *stub, bool isForOp) {
@@ -91,16 +98,30 @@ class BaselineCompilerShared
     bool addICLoadLabel(CodeOffsetLabel label) {
         JS_ASSERT(!icEntries_.empty());
         ICLoadLabel loadLabel;
         loadLabel.label = label;
         loadLabel.icEntry = icEntries_.length() - 1;
         return icLoadLabels_.append(loadLabel);
     }
 
+    BlockCounterEntry *allocateBlockCounterEntry(const size_t pcoffset) {
+        if(!blockCounterEntries_.append(BlockCounterEntry(pcoffset)))
+            return NULL;
+        return &blockCounterEntries_.back();
+    }
+
+    bool addBlockCounterLabel(CodeOffsetLabel label) {
+        JS_ASSERT(!blockCounterEntries_.empty());
+        BlockCounterLabel bcLabel;
+        bcLabel.label = label;
+        bcLabel.bcEntry = blockCounterEntries_.length() - 1;
+        return blockCounterLabels_.append(bcLabel);
+    }
+
     JSFunction *function() const {
         return script->function();
     }
 
     PCMappingSlotInfo getStackTopSlotInfo() {
         JS_ASSERT(frame.numUnsyncedSlots() <= 2);
         switch (frame.numUnsyncedSlots()) {
           case 0:
diff --git a/js/src/shell/js.cpp b/js/src/shell/js.cpp
--- a/js/src/shell/js.cpp
+++ b/js/src/shell/js.cpp
@@ -5096,16 +5096,25 @@ ProcessArgs(JSContext *cx, JSObject *obj
 
     useCount = op->getIntOption("baseline-uses-before-compile");
     if (useCount >= 0)
         ion::js_IonOptions.baselineUsesBeforeCompile = useCount;
 
     if (op->getBoolOption("baseline-eager"))
         ion::js_IonOptions.baselineUsesBeforeCompile = 0;
 
+    if (const char *str = op->getStringOption("branch-profiling")) {
+        if (strcmp(str, "off") == 0)
+            ion::js_IonOptions.baselineBranchProfiling = false;
+        else if (strcmp(str, "on") == 0)
+            ion::js_IonOptions.baselineBranchProfiling = true;
+        else
+            return OptionFailure("branch-profiling", str);
+    }
+
     if (const char *str = op->getStringOption("ion-regalloc")) {
         if (strcmp(str, "lsra") == 0)
             ion::js_IonOptions.registerAllocator = ion::RegisterAllocator_LSRA;
         else if (strcmp(str, "backtracking") == 0)
             ion::js_IonOptions.registerAllocator = ion::RegisterAllocator_Backtracking;
         else if (strcmp(str, "stupid") == 0)
             ion::js_IonOptions.registerAllocator = ion::RegisterAllocator_Stupid;
         else
@@ -5352,16 +5361,18 @@ main(int argc, char **argv, char **envp)
         || !op.addIntOption('\0', "ion-uses-before-compile", "COUNT",
                             "Wait for COUNT calls or iterations before compiling "
                             "(default: 1000)", -1)
         || !op.addStringOption('\0', "ion-regalloc", "[mode]",
                                "Specify Ion register allocation:\n"
                                "  lsra: Linear Scan register allocation (default)\n"
                                "  backtracking: Priority based backtracking register allocation\n"
                                "  stupid: Simple block local register allocation")
+        || !op.addStringOption('\0', "branch-profiling", "on/off",
+                               "Profile baseline generated codes (default: on, off to disable)")
         || !op.addBoolOption('\0', "ion-eager", "Always ion-compile methods (implies --baseline-eager)")
 #ifdef JS_THREADSAFE
         || !op.addStringOption('\0', "ion-parallel-compile", "on/off",
                                "Compile scripts off thread (default: off)")
 #endif
         || !op.addBoolOption('\0', "baseline", "Enable baseline compiler (default)")
         || !op.addBoolOption('\0', "no-baseline", "Disable baseline compiler")
         || !op.addBoolOption('\0', "baseline-eager", "Always baseline-compile methods")
