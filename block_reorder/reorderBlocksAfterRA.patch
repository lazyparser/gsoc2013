# HG changeset patch
# Parent aa8de5cbf6efd6ac29409f832b92ff83a981f858
# User Wei Wu <lazyparser@gmail.com>

diff --git a/js/src/ion/Ion.cpp b/js/src/ion/Ion.cpp
--- a/js/src/ion/Ion.cpp
+++ b/js/src/ion/Ion.cpp
@@ -1270,16 +1270,23 @@ GenerateCode(MIRGenerator *mir, LIRGraph
         return NULL;
 
     if (mir->compilingAsmJS()) {
         if (!codegen->generateAsmJS()) {
             js_delete(codegen);
             return NULL;
         }
     } else {
+        if (js_IonOptions.baselineBranchProfiling && js_IonOptions.moveUnlikelyBlocks) {
+            if (!MoveUnlikelyBlocks(lir)) {
+                js_delete(codegen);
+                return NULL;
+            }
+        }
+
         if (!codegen->generate()) {
             js_delete(codegen);
             return NULL;
         }
     }
 
     return codegen;
 }
diff --git a/js/src/ion/Ion.h b/js/src/ion/Ion.h
--- a/js/src/ion/Ion.h
+++ b/js/src/ion/Ion.h
@@ -179,21 +179,31 @@ struct IonOptions
     // Default: 1
     uint32_t usesBeforeCompilePar;
 
     // Whether baseline scripts are instrumented.
     //
     // Default: false
     bool baselineBranchProfiling;
 
+    // Toggles whether LIR Blocks are reordered based on branch profiles.
+    //
+    // Default: true iff baselineBranchProfiling is true.
+    bool moveUnlikelyBlocks;
+
     void setEagerCompilation() {
         eagerCompilation = true;
         usesBeforeCompile = 0;
         baselineUsesBeforeCompile = 0;
 
+        // Disable branch profiling and related optimizitions.
+        // This is for testing only.
+        baselineBranchProfiling = false;
+        moveUnlikelyBlocks = false;
+
         parallelCompilation = false;
     }
 
     IonOptions()
       : gvn(true),
         gvnIsOptimistic(true),
         licm(true),
         osr(true),
@@ -214,17 +224,20 @@ struct IonOptions
         maxInlineDepth(3),
         smallFunctionMaxInlineDepth(10),
         smallFunctionMaxBytecodeLength(100),
         polyInlineMax(4),
         inlineMaxTotalBytecodeLength(1000),
         inlineUseCountRatio(128),
         eagerCompilation(false),
         usesBeforeCompilePar(1),
-        baselineBranchProfiling(false)
+        // these modifications are for test only.
+        // it will not be included in the final patch.
+        baselineBranchProfiling(true),
+        moveUnlikelyBlocks(true)
     {
     }
 
     uint32_t usesBeforeInlining() {
         return usesBeforeCompile * usesBeforeInliningFactor;
     }
 };
 
diff --git a/js/src/ion/IonAnalysis.cpp b/js/src/ion/IonAnalysis.cpp
--- a/js/src/ion/IonAnalysis.cpp
+++ b/js/src/ion/IonAnalysis.cpp
@@ -93,16 +93,51 @@ ion::AttachBranchProfiles(MIRGraph &grap
                 block->setBlockUseCount(entry.counter);
                 break;
             }
         }
     }
     return true;
 }
 
+bool
+ion::MoveUnlikelyBlocks(LIRGraph *lir)
+{
+    LBlockVector likelyBlocks;
+    LBlockVector unlikelyBlocks;
+
+    // The entry block must remain in the first place.
+    JS_ASSERT(lir->numBlocks());
+    if (!likelyBlocks.append(lir->getBlock(0)))
+        return false;
+
+    for (size_t i = 1; i < lir->numBlocks(); i++) {
+        LBlock *lblock = lir->getBlock(i);
+        JS_ASSERT(lblock);
+        MBasicBlock *mblock = lblock->mir();
+        JS_ASSERT(mblock);
+
+        // TODO: Extract this condition and place it in a separated function
+        // which would be call something like "unlikelyBlockHeurisitic".
+        //
+        // Currently use this naive heuristic instead.
+        if (mblock->isBlockUseCountAvailable() && mblock->getBlockUseCount() == 0) {
+            if (!unlikelyBlocks.append(lblock))
+                return false;
+        } else {
+            if (!likelyBlocks.append(lblock))
+                return false;
+        }
+    }
+
+    lir->replaceBlocksByLikelyhood(likelyBlocks, unlikelyBlocks);
+
+    return true;
+}
+
 // Operands to a resume point which are dead at the point of the resume can be
 // replaced with undefined values. This analysis supports limited detection of
 // dead operands, pruning those which are defined in the resume point's basic
 // block and have no uses outside the block or at points later than the resume
 // point.
 //
 // This is intended to ensure that extra resume points within a basic block
 // will not artificially extend the lifetimes of any SSA values. This could
diff --git a/js/src/ion/IonAnalysis.h b/js/src/ion/IonAnalysis.h
--- a/js/src/ion/IonAnalysis.h
+++ b/js/src/ion/IonAnalysis.h
@@ -20,16 +20,19 @@ class MIRGraph;
 
 bool
 SplitCriticalEdges(MIRGraph &graph);
 
 bool
 AttachBranchProfiles(MIRGraph &graph);
 
 bool
+MoveUnlikelyBlocks(LIRGraph *lir);
+
+bool
 isAsmJSCompilation(MIRGraph &graph);
 
 enum Observability {
     ConservativeObservability,
     AggressiveObservability
 };
 
 bool
diff --git a/js/src/ion/LIR.cpp b/js/src/ion/LIR.cpp
--- a/js/src/ion/LIR.cpp
+++ b/js/src/ion/LIR.cpp
@@ -45,16 +45,51 @@ LIRGraph::noteNeedsSafepoint(LInstructio
 }
 
 void
 LIRGraph::removeBlock(size_t i)
 {
     blocks_.erase(blocks_.begin() + i);
 }
 
+void
+LIRGraph::replaceBlocksByLikelyhood(LBlockVector &likelyBlocks, LBlockVector &unlikelyBlocks)
+{
+    // TODO: replace with mozilla::DebugOnly<size_t> num = numBlocks();
+    // size_t num = numBlocks();
+    mozilla::DebugOnly<size_t> num = numBlocks();
+    JS_ASSERT(num == likelyBlocks.length() + unlikelyBlocks.length());
+    JS_ASSERT(getBlock(0) == likelyBlocks[0]);
+
+    blocks_.clear();
+
+    mozilla::DebugOnly<bool> success;
+    success = blocks_.appendAll(likelyBlocks);
+    JS_ASSERT(success);
+    success = blocks_.appendAll(unlikelyBlocks);
+    JS_ASSERT(success);
+
+    JS_ASSERT(num == numBlocks());
+
+    renumberMBlocks();
+}
+
+bool
+LIRGraph::renumberMBlocks()
+{
+    IonSpew(IonSpew_BranchProfiles, "LIRGraph::renumberMBlocks()");
+    for (size_t i = 0; i < numBlocks(); i++) {
+        IonSpew(IonSpew_BranchProfiles, "LBlock.MBlock.id: %d -> %d",
+                getBlock(i)->mir()->id(), i);
+        getBlock(i)->mir()->setId(i);
+    }
+
+    return true;
+}
+
 Label *
 LBlock::label()
 {
     return begin()->toLabel()->label();
 }
 
 uint32_t
 LBlock::firstId()
diff --git a/js/src/ion/LIR.h b/js/src/ion/LIR.h
--- a/js/src/ion/LIR.h
+++ b/js/src/ion/LIR.h
@@ -722,16 +722,17 @@ class LInstructionVisitor
   public:
 #define VISIT_INS(op) virtual bool visit##op(L##op *) { MOZ_ASSUME_UNREACHABLE("NYI: " #op); }
     LIR_OPCODE_LIST(VISIT_INS)
 #undef VISIT_INS
 };
 
 typedef InlineList<LInstruction>::iterator LInstructionIterator;
 typedef InlineList<LInstruction>::reverse_iterator LInstructionReverseIterator;
+typedef Vector<LBlock *, 4, SystemAllocPolicy> LBlockVector;
 
 class LPhi;
 class LMoveGroup;
 class LBlock : public TempObject
 {
     MBasicBlock *block_;
     Vector<LPhi *, 4, IonAllocPolicy> phis_;
     InlineList<LInstruction> instructions_;
@@ -1420,16 +1421,20 @@ class LIRGraph
     }
     size_t numSafepoints() const {
         return safepoints_.length();
     }
     LInstruction *getSafepoint(size_t i) const {
         return safepoints_[i];
     }
     void removeBlock(size_t i);
+
+    void replaceBlocksByLikelyhood(LBlockVector &likelyBlocks, LBlockVector &unlikelyBlocks);
+
+    bool renumberMBlocks();
 };
 
 LAllocation::LAllocation(const AnyRegister &reg)
 {
     if (reg.isFloat())
         *this = LFloatReg(reg.fpu());
     else
         *this = LGeneralReg(reg.gpr());
