# HG changeset patch
# Parent fcec9ae54be3fe229b6cd478d8a5b3e963c8126c
# User Wei Wu <lazyparser@gmail.com>

diff --git a/js/src/jit/CodeGenerator.cpp b/js/src/jit/CodeGenerator.cpp
--- a/js/src/jit/CodeGenerator.cpp
+++ b/js/src/jit/CodeGenerator.cpp
@@ -983,17 +983,17 @@ CodeGenerator::visitReturn(LReturn *lir)
     DebugOnly<LAllocation *> payload = lir->getOperand(PAYLOAD_INDEX);
     JS_ASSERT(ToRegister(type)    == JSReturnReg_Type);
     JS_ASSERT(ToRegister(payload) == JSReturnReg_Data);
 #elif defined(JS_PUNBOX64)
     DebugOnly<LAllocation *> result = lir->getOperand(0);
     JS_ASSERT(ToRegister(result) == JSReturnReg);
 #endif
     // Don't emit a jump to the return label if this is the last block.
-    if (current->mir() != *gen->graph().poBegin())
+    if (current != graph.getBlock(graph.numBlocks() - 1))
         masm.jump(&returnLabel_);
     return true;
 }
 
 bool
 CodeGenerator::visitOsrEntry(LOsrEntry *lir)
 {
     // Remember the OSR entry offset into the code buffer.
diff --git a/js/src/jit/Ion.cpp b/js/src/jit/Ion.cpp
--- a/js/src/jit/Ion.cpp
+++ b/js/src/jit/Ion.cpp
@@ -1479,16 +1479,24 @@ GenerateCode(MIRGenerator *mir, LIRGraph
         return NULL;
 
     if (mir->compilingAsmJS()) {
         if (!codegen->generateAsmJS()) {
             js_delete(codegen);
             return NULL;
         }
     } else {
+        if (js_IonOptions.moveUnlikelyBlocks) {
+            if (!MoveUnlikelyBlocks(mir, lir)) {
+                js_delete(codegen);
+                return NULL;
+            }
+            IonSpewPass("Move Unlikely Blocks");
+        }
+
         if (!codegen->generate()) {
             js_delete(codegen);
             return NULL;
         }
     }
 
     return codegen;
 }
diff --git a/js/src/jit/Ion.h b/js/src/jit/Ion.h
--- a/js/src/jit/Ion.h
+++ b/js/src/jit/Ion.h
@@ -196,21 +196,41 @@ struct IonOptions
     //
     // Default: 1
     uint32_t usesBeforeCompilePar;
 
     // Whether baseline scripts are instrumented.
     //
     // Default: false
     bool baselineBranchProfiling;
-   
+
+    // Toggles whether LIR Blocks are reordered based on branch profiles.
+    //
+    // Default: true if baselineBranchProfiling is true.
+    bool moveUnlikelyBlocks;
+
+    // How many iterations should be profiled before we move LBlocks.
+    //
+    // Default: 300
+    uint32_t unlikelyBlockUseCountThreshold;
+
+    // A branch is marked 'unlikely' if its execution probability is lower than this ratio.
+    //
+    // Default: 0.05
+    double unlikelyBlockUseCountRatio;
+
     void setEagerCompilation() {
         eagerCompilation = true;
         usesBeforeCompile = 0;
         baselineUsesBeforeCompile = 0;
+
+        // Disable branch profiling and related optimizations.
+        // This is for testing only.
+        baselineBranchProfiling = false;
+        moveUnlikelyBlocks = false;
     }
 
     IonOptions()
       : gvn(true),
         gvnIsOptimistic(true),
         licm(true),
         osr(true),
         limitScriptSize(true),
@@ -235,17 +255,21 @@ struct IonOptions
         maxInlineDepth(3),
         smallFunctionMaxInlineDepth(10),
         smallFunctionMaxBytecodeLength(100),
         polyInlineMax(4),
         inlineMaxTotalBytecodeLength(1000),
         inlineUseCountRatio(128),
         eagerCompilation(false),
         usesBeforeCompilePar(1),
-        baselineBranchProfiling(true)
+        // Enabled by default for testing purpose.
+        baselineBranchProfiling(true),
+        moveUnlikelyBlocks(true),
+        unlikelyBlockUseCountThreshold(300),
+        unlikelyBlockUseCountRatio(0.05)
     {
     }
 
     uint32_t usesBeforeInlining() {
         return usesBeforeCompile * usesBeforeInliningFactor;
     }
 };
 
diff --git a/js/src/jit/IonAnalysis.cpp b/js/src/jit/IonAnalysis.cpp
--- a/js/src/jit/IonAnalysis.cpp
+++ b/js/src/jit/IonAnalysis.cpp
@@ -279,16 +279,138 @@ jit::AttachBranchProfiles(MIRGenerator *
                     "AttachBranchProfiles mismatch jsscript(%p) -> block %d",
                     block->info().script(), block->id(), block->pc() - block->info().startPC());
         }
     }
 #endif
     return true;
 }
 
+bool
+jit::MoveUnlikelyBlocks(MIRGenerator *mir, LIRGraph *lir)
+{
+    // Forbid AsmJS optimization as OdinMonkey is an ahead of time compiler
+    // and we do not have any profiled information.
+    JS_ASSERT(!mir->compilingAsmJS());
+
+    MIRGraph &mgraph = lir->mir();
+    mgraph.unmarkBlocks();
+    Vector<MBasicBlock *, 8, SystemAllocPolicy> worklist;
+
+    MBasicBlock *entryBlock = mgraph.entryBlock();
+    JS_ASSERT(entryBlock);
+    entryBlock->mark();
+    if (!worklist.append(entryBlock))
+        return false;
+
+    MBasicBlock *osrBlock = mgraph.osrBlock();
+    if (osrBlock)
+        if (!worklist.append(osrBlock))
+            return false;
+
+    const uint32_t useCountThreshold = js_IonOptions.unlikelyBlockUseCountThreshold;
+
+    while (worklist.length()) {
+        MBasicBlock *block = worklist.popCopy();
+        JS_ASSERT(block);
+        size_t numSucc = block->numSuccessors();
+        JSScript *jsscript = block->info().script();
+
+        if (numSucc == 0)
+            continue;
+
+        // If the block has only one successor, then the successor will definitely be executed.
+        if (numSucc == 1) {
+            MBasicBlock *succ = block->getSuccessor(0);
+            if (!succ->isMarked()) {
+                succ->mark();
+                if (!worklist.append(succ))
+                    return false;
+            }
+            continue;
+        }
+        uint32_t sum = 0;
+        for (size_t i = 0; i < numSucc; i++) {
+            MBasicBlock *succ = block->getSuccessor(i);
+            if (succ->isBlockUseCountAvailable())
+                sum += succ->getBlockUseCount();
+        }
+
+        // If the iterations we have seen is less than the default threshold, e.g.
+        // less than 300 iterations, we do not have enough samples to make any wise choice.
+        // In this case we just assume that all successors are likely.
+        //
+        // Currently the successors of the basic block which has 'TableSwitch' or
+        // 'CondSwitch' as its last instruction do not have correct profiles,
+        // so we assume that all successors are likely.
+        if (sum < useCountThreshold || block->lastIns()->isTableSwitch()) {
+            for (size_t i = 0; i < numSucc; i++) {
+                MBasicBlock *succ = block->getSuccessor(i);
+                if (!succ->isMarked()) {
+                    succ->mark();
+                    if (!worklist.append(succ))
+                        return false;
+                }
+            }
+            continue;
+        }
+
+        const double branchLikelyRatio = js_IonOptions.unlikelyBlockUseCountRatio * sum / numSucc;
+        for (size_t i = 0; i < numSucc; i++) {
+            MBasicBlock *succ = block->getSuccessor(i);
+            if (succ->isMarked())
+                continue;
+
+            if (!succ->isBlockUseCountAvailable() ||
+                    block->loopDepth() > succ->loopDepth() ||
+                    block->isLoopHeader() ||
+                    succ->getBlockUseCount() > branchLikelyRatio) {
+                succ->mark();
+                if (!worklist.append(succ))
+                    return false;
+                continue;
+            }
+
+            JS_ASSERT_IF(succ->isMarked() && succ->immediateDominator(), succ->immediateDominator()->isMarked());
+        }
+
+#ifdef DEBUG
+        // If the block is marked, then at least on successor should be marked.
+        size_t numMarked = 0;
+        for (size_t j = 0; j < numSucc; j++) {
+            if (block->getSuccessor(j)->isMarked())
+                numMarked++;
+        }
+        JS_ASSERT(numMarked);
+#endif
+    }
+
+    LBlockVector likelyBlocks;
+    LBlockVector unlikelyBlocks;
+
+    for (MBasicBlockIterator iter(mgraph.begin()); iter != mgraph.end(); iter++) {
+        if (iter->isMarked()) {
+            if (!likelyBlocks.append(iter->lir()))
+                return false;
+        } else {
+            if (!unlikelyBlocks.append(iter->lir()))
+                return false;
+        }
+    }
+    IonSpew(IonSpew_BranchProfiles,
+            "MoveUnlikelyBlocks likely = %u, unlikely = %u @ %s:%d",
+            likelyBlocks.length(), unlikelyBlocks.length(),
+            mir->info().script()->filename(), mir->info().lineno());
+
+
+    lir->replaceBlocksByLikelyhood(likelyBlocks, unlikelyBlocks);
+
+    return true;
+}
+
 // Operands to a resume point which are dead at the point of the resume can be
 // replaced with undefined values. This analysis supports limited detection of
 // dead operands, pruning those which are defined in the resume point's basic
 // block and have no uses outside the block or at points later than the resume
 // point.
 //
 // This is intended to ensure that extra resume points within a basic block
 // will not artificially extend the lifetimes of any SSA values. This could
diff --git a/js/src/jit/IonAnalysis.h b/js/src/jit/IonAnalysis.h
--- a/js/src/jit/IonAnalysis.h
+++ b/js/src/jit/IonAnalysis.h
@@ -63,16 +63,19 @@ bool
 EliminateRedundantChecks(MIRGraph &graph);
 
 bool
 UnsplitEdges(LIRGraph *lir);
 
 bool
 PropagatePushedArguments(LIRGraph *lir);
 
+bool
+MoveUnlikelyBlocks(MIRGenerator *mir, LIRGraph *lir);
+
 class MDefinition;
 
 // Simple linear sum of the form 'n' or 'x + n'.
 struct SimpleLinearSum
 {
     MDefinition *term;
     int32_t constant;
 
diff --git a/js/src/jit/LIR.cpp b/js/src/jit/LIR.cpp
--- a/js/src/jit/LIR.cpp
+++ b/js/src/jit/LIR.cpp
@@ -47,16 +47,54 @@ LIRGraph::noteNeedsSafepoint(LInstructio
 }
 
 void
 LIRGraph::removeBlock(size_t i)
 {
     blocks_.erase(blocks_.begin() + i);
 }
 
+void
+LIRGraph::replaceBlocksByLikelyhood(LBlockVector &likelyBlocks, LBlockVector &unlikelyBlocks)
+{
+    mozilla::DebugOnly<size_t> num = numBlocks();
+    JS_ASSERT(num == likelyBlocks.length() + unlikelyBlocks.length());
+    JS_ASSERT(getBlock(0) == likelyBlocks[0]);
+
+    // Just return if there are no blocks should be moved.
+    if (!unlikelyBlocks.length())
+        return;
+
+    blocks_.clear();
+
+    mozilla::DebugOnly<bool> success;
+    success = blocks_.appendAll(likelyBlocks);
+    JS_ASSERT(success);
+    success = blocks_.appendAll(unlikelyBlocks);
+    JS_ASSERT(success);
+
+    JS_ASSERT(num == numBlocks());
+
+    renumberMBlocks();
+}
+
+bool
+LIRGraph::renumberMBlocks()
+{
+    IonSpew(IonSpew_BranchProfiles, "Entering LIRGraph::renumberMBlocks()");
+    for (size_t i = 0; i < numBlocks(); i++) {
+        MBasicBlock *block = getBlock(i)->mir();
+        JS_ASSERT(block);
+        IonSpew(IonSpew_BranchProfiles, "LBlock->MBlock->id: %d -> %d", block->id(), i);
+        block->setId(i);
+    }
+
+    return true;
+}
+
 Label *
 LBlock::label()
 {
     return begin()->toLabel()->label();
 }
 
 uint32_t
 LBlock::firstId()
diff --git a/js/src/jit/LIR.h b/js/src/jit/LIR.h
--- a/js/src/jit/LIR.h
+++ b/js/src/jit/LIR.h
@@ -725,16 +725,17 @@ class LInstructionVisitor
   public:
 #define VISIT_INS(op) virtual bool visit##op(L##op *) { MOZ_ASSUME_UNREACHABLE("NYI: " #op); }
     LIR_OPCODE_LIST(VISIT_INS)
 #undef VISIT_INS
 };
 
 typedef InlineList<LInstruction>::iterator LInstructionIterator;
 typedef InlineList<LInstruction>::reverse_iterator LInstructionReverseIterator;
+typedef Vector<LBlock *, 4, SystemAllocPolicy> LBlockVector;
 
 class LPhi;
 class LMoveGroup;
 class LBlock : public TempObject
 {
     MBasicBlock *block_;
     Vector<LPhi *, 4, IonAllocPolicy> phis_;
     InlineList<LInstruction> instructions_;
@@ -1440,16 +1441,20 @@ class LIRGraph
     }
     size_t numSafepoints() const {
         return safepoints_.length();
     }
     LInstruction *getSafepoint(size_t i) const {
         return safepoints_[i];
     }
     void removeBlock(size_t i);
+
+    void replaceBlocksByLikelyhood(LBlockVector &likelyBlocks, LBlockVector &unlikelyBlocks);
+
+    bool renumberMBlocks();
 };
 
 LAllocation::LAllocation(const AnyRegister &reg)
 {
     if (reg.isFloat())
         *this = LFloatReg(reg.fpu());
     else
         *this = LGeneralReg(reg.gpr());
